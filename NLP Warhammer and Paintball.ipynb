{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models for Smash and Warhammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for modeling\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#silence future warnings becuase they're annoying\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subreddits to use for model\n",
    "sub1 = 'Warhammer40k'\n",
    "sub2 = 'paintball'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "data1 = pd.read_csv(sub1+'.csv')\n",
    "data2 = pd.read_csv(sub2+'.csv')\n",
    "\n",
    "#creating column indicating which sub a post is from\n",
    "data1['subreddit'] = 1\n",
    "data2['subreddit'] = 0\n",
    "df = pd.concat([data1,data2])\n",
    "\n",
    "#defining features and target variable\n",
    "X = df['data']\n",
    "y = df['subreddit']\n",
    "\n",
    "#train test split to be used for all models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "1. [Logistic Regression](#model1) Best Accuracy: 90.98% (TF-IDF)\n",
    "2. [KNN](#model2) Best Accuracy: 89.29% (TF-IDF)\n",
    "3. [Multinomial Naive Bayes](#model3) Best Accuracy: 93.39% (Count)\n",
    "\n",
    "Most hyperparamters were found by experimentation in gridsearch using binary search algorithm. This method assumes that effects of a given hyperparameter are linear, which may not always be the case, but does always converge to a local optimizer regardless  \n",
    "\n",
    "For reference:  \n",
    "https://en.wikipedia.org/wiki/Binary_search_algorithm\n",
    "\n",
    "In essence, \n",
    "- test between 2 values, that are arbitrary percieved bounds\n",
    "- keep the one that gives a higher score and replace the other with the average of the 2 values\n",
    "- test between previous best and average as new values\n",
    "- repeat until convergence\n",
    "\n",
    "(Didn't go into the 50's or decimals, so stopped algorithm early to keep things even)\n",
    "\n",
    "Gridsearch was used, but it optimizes for Cross Val Score, I optimized for test set accuracy instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1: Logistic Regression\n",
    "<a id='model1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words='english')),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'vec': [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')],\n",
    "    'vec__max_features': [2700,2800], #tried [3000, 3100, 3200,]\n",
    "    'vec__min_df': [2],\n",
    "    'vec__max_df': [.9,.85],\n",
    "    'vec__ngram_range': [(1,3),(1,2)],\n",
    "    'lr__C': [1,2,3], #tried [1,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvs: 0.891566265060241\n",
      "train score: 0.9825970548862115\n",
      "test score: 0.9098196392785571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 2,\n",
       " 'vec': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=0.9, max_features=2700,\n",
       "                 min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                 sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, use_idf=True, vocabulary=None),\n",
       " 'vec__max_df': 0.9,\n",
       " 'vec__max_features': 2700,\n",
       " 'vec__min_df': 2,\n",
       " 'vec__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score on testing set was 90.98% accuracy, using TF-IDF, which is a little lower than models based on the other subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: k-Nearest Neighbors\n",
    "<a id='model2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words='english')),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'vec': [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')],\n",
    "    'vec__max_features': [3000, 3100],\n",
    "    'vec__min_df': [2],\n",
    "    'vec__max_df': [.9],\n",
    "    'vec__ngram_range': [(1,1),(1,2)],\n",
    "    'knn__n_neighbors': [35]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvs: 0.8714859437751004\n",
      "train score: 0.8969210174029452\n",
      "test score: 0.8937875751503006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 35,\n",
       " 'vec': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=0.9, max_features=3000,\n",
       "                 min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                 sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, use_idf=True, vocabulary=None),\n",
       " 'vec__max_df': 0.9,\n",
       " 'vec__max_features': 3000,\n",
       " 'vec__min_df': 2,\n",
       " 'vec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managed to get a training and test score around 89.27% which is comparable to logistic regression, despite it performing worse with this data in comparison tot he other two subreddit combinations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3: Multinomial Naive Bayes\n",
    "<a id='model3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Guassian is too computationally expensive as it requires a dense matrix not a sparse one. Attempting multinomial to see what happens as the matrix is sparse anyways it violates fewer assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'vec': [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')],\n",
    "    'vec__max_features': [3500],\n",
    "    'vec__min_df': [2],\n",
    "    'vec__max_df': [.9],\n",
    "    'vec__ngram_range': [(1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvs: 0.9062918340026773\n",
      "train score: 0.9591700133868809\n",
      "test score: 0.9338677354709419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=0.9, max_features=3500, min_df=2,\n",
       "                 ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, vocabulary=None),\n",
       " 'vec__max_df': 0.9,\n",
       " 'vec__max_features': 3500,\n",
       " 'vec__min_df': 2,\n",
       " 'vec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved and accuracy of 93.39%. Slightly higher cvs score was acheived with lowermax_features down to 3000, but also lowered accuracy. Count vectorizer was found to be better for once. Once again naive bayes is the most effective model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
