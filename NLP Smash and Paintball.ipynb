{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models for Smash and Warhammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for modeling\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#silence future warnings becuase they're annoying\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(991, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subreddits to use for model\n",
    "sub1 = 'smashbros'\n",
    "sub2 = 'paintball'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "data1 = pd.read_csv(sub1+'.csv')\n",
    "data2 = pd.read_csv(sub2+'.csv')\n",
    "\n",
    "#creating column indicating which sub a post is from\n",
    "data1['subreddit'] = 1\n",
    "data2['subreddit'] = 0\n",
    "df = pd.concat([data1,data2])\n",
    "\n",
    "#defining features and target variable\n",
    "X = df['data']\n",
    "y = df['subreddit']\n",
    "\n",
    "#train test split to be used for all models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = text.ENGLISH_STOP_WORDS.union(['amp', 'new', 'like', 'got','know','just', 've','don', 'think'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "1. [Logistic Regression](#model1) Best Accuracy: 91.93% (TF-IDF)\n",
    "2. [KNN](#model2) Best Accuracy: 82.29% (TF-IDF)\n",
    "3. [Multinomial Naive Bayes](#model3) Best Accuracy: 92.54% (TF-IDF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1: Logistic Regression\n",
    "<a id='model1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words='english')),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'vec': [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')],\n",
    "    'vec__max_features': [2500,3000, 3500], #tried [3000, 3100, 3200,]\n",
    "    'vec__min_df': [2],\n",
    "    'vec__max_df': [.8,.85],\n",
    "    'vec__ngram_range': [(1,1),(1,2)],\n",
    "    'lr__C': [1,5], #tried [1,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvs: 0.9422043010752689\n",
      "train score: 0.9852150537634409\n",
      "test score: 0.9193548387096774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 1,\n",
       " 'vec': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=0.8, max_features=3000,\n",
       "                 min_df=2, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                 sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, use_idf=True, vocabulary=None),\n",
       " 'vec__max_df': 0.8,\n",
       " 'vec__max_features': 3000,\n",
       " 'vec__min_df': 2,\n",
       " 'vec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score on testing set was 91.93% accuracy, using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: k-Nearest Neighbors\n",
    "<a id='model2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words='english')),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'vec': [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')],\n",
    "    'vec__max_features': [3200],\n",
    "    'vec__min_df': [2],\n",
    "    'vec__max_df': [.9],\n",
    "    'vec__ngram_range': [(1,1)],\n",
    "    'knn__n_neighbors': [35]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvs: 0.8723118279569892\n",
      "train score: 0.8958333333333334\n",
      "test score: 0.8629032258064516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 35,\n",
       " 'vec': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=0.9, max_features=3200,\n",
       "                 min_df=2, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                 sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, use_idf=True, vocabulary=None),\n",
       " 'vec__max_df': 0.9,\n",
       " 'vec__max_features': 3200,\n",
       " 'vec__min_df': 2,\n",
       " 'vec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managed to get a training and test score around 82.29%, however, max features of 3100 gave a slightly higher cross val score but lower accurcy. Interestingly, scores in the lower 80's were common no matter what was changed among hypter parameters, but in the Smash and Warhammer model the accuracy was more sporadic with kNN and also lower, despite logistic regression yielding better scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3: Multinomial Naive Bayes\n",
    "<a id='model3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Guassian is too computationally expensive as it requires a dense matrix not a sparse one. Attempting multinomial to see what happens as the matrix is sparse anyways it violates fewer assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'vec': [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')],\n",
    "    'vec__max_features': [3900, 4000],\n",
    "    'vec__min_df': [2],\n",
    "    'vec__max_df': [.9],\n",
    "    'vec__ngram_range': [(1,2), (1,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvs: 0.9435483870967742\n",
      "train score: 0.9811827956989247\n",
      "test score: 0.9254032258064516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=0.9, max_features=3900,\n",
       "                 min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                 sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, use_idf=True, vocabulary=None),\n",
       " 'vec__max_df': 0.9,\n",
       " 'vec__max_features': 3900,\n",
       " 'vec__min_df': 2,\n",
       " 'vec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved and accuracy of 92.54% on the test set, which so far is the best model in comparison to the other 2, but is still quite a bit worse than with the smash warhamer mode."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
