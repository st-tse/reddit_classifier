{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models for Smash and Warhammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for modeling\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#silence future warnings becuase they're annoying\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subreddits to use for model\n",
    "sub1 = 'smashbros'\n",
    "sub2 = 'warhammer40k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "data1 = pd.read_csv(sub1+'.csv')\n",
    "data2 = pd.read_csv(sub2+'.csv')\n",
    "\n",
    "#creating column indicating which sub a post is from\n",
    "data1['subreddit'] = 1\n",
    "data2['subreddit'] = 0\n",
    "df = pd.concat([data1,data2])\n",
    "\n",
    "#defining features and target variable\n",
    "X = df['data']\n",
    "y = df['subreddit']\n",
    "\n",
    "#train test split to be used for all models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = text.ENGLISH_STOP_WORDS.union(['amp', 'new', 'like', 'got','know','just', 've','don', 'think'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "1. [Logistic Regression](#model1) Best Accuracy: 94.78% (TF-IDF)\n",
    "2. [KNN](#model2) Best Accuracy: 71.49% (TF-IDF)\n",
    "3. [Multinomial Naive Bayes](#model3) Best Accuracy: 95.78% (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1: Logistic Regression\n",
    "<a id='model1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words='english')),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'vec': [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')],\n",
    "    'vec__max_features': [3300, 3400], #tried [3000, 3100, 3200,]\n",
    "    'vec__min_df': [2, 3],\n",
    "    'vec__max_df': [.9],\n",
    "    'vec__ngram_range': [(1,3)],\n",
    "    'lr__C': [6,7], #tried [1,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvs: 0.9229738780977896\n",
      "train score: 0.9926322839919625\n",
      "test score: 0.9477911646586346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 6,\n",
       " 'vec': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=0.9, max_features=3300,\n",
       "                 min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                 sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, use_idf=True, vocabulary=None),\n",
       " 'vec__max_df': 0.9,\n",
       " 'vec__max_features': 3300,\n",
       " 'vec__min_df': 2,\n",
       " 'vec__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score on testing set was 94.78% accuracy, using TF-IDF. Worth noting is that n-gram range of (1,3) yielded a worse cross-validation score but a better test set accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: k-Nearest Neighbors\n",
    "<a id='model2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words='english')),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'vec': [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')],\n",
    "    'vec__max_features': [3500, 3600],\n",
    "    'vec__min_df': [2],\n",
    "    'vec__max_df': [.9],\n",
    "    'vec__ngram_range': [(1,1)],\n",
    "    'knn__n_neighbors': [35]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvs: 0.87073007367716\n",
      "train score: 0.7273945077026122\n",
      "test score: 0.714859437751004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 35,\n",
       " 'vec': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=0.9, max_features=3500,\n",
       "                 min_df=2, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                 sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, use_idf=True, vocabulary=None),\n",
       " 'vec__max_df': 0.9,\n",
       " 'vec__max_features': 3500,\n",
       " 'vec__min_df': 2,\n",
       " 'vec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managed to get a training and test score around 71%, however, any slight deviation in the hyperparamters drops accuray to the 50s. This model is worse than linear regression is bascially everyway possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3: Multinomial Naive Bayes\n",
    "<a id='model3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Guassian is too computationally expensive as it requires a dense matrix not a sparse one. Attempting multinomial to see what happens as the matrix is sparse anyways it violates fewer assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'vec': [CountVectorizer(stop_words='english'), TfidfVectorizer(stop_words='english')],\n",
    "    'vec__max_features': [3300, 3400, 3500],\n",
    "    'vec__min_df': [2, 3],\n",
    "    'vec__max_df': [.9],\n",
    "    'vec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvs: 0.9390488948425988\n",
      "train score: 0.9886135298057602\n",
      "test score: 0.9538152610441767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=0.9, max_features=3400,\n",
       "                 min_df=2, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True,\n",
       "                 stop_words=frozenset({'a', 'about', 'above', 'across', 'after',\n",
       "                                       'afterwards', 'again', 'against', 'all',\n",
       "                                       'almost', 'alone', 'along', 'already',\n",
       "                                       'also', 'although', 'always', 'am',\n",
       "                                       'among', 'amongst', 'amoungst', 'amount',\n",
       "                                       'amp', 'an', 'and', 'another', 'any',\n",
       "                                       'anyhow', 'anyone', 'anything', 'anyway', ...}),\n",
       "                 strip_accents=None, sublinear_tf=False,\n",
       "                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "                 vocabulary=None),\n",
       " 'vec__max_df': 0.9,\n",
       " 'vec__max_features': 3400,\n",
       " 'vec__min_df': 2,\n",
       " 'vec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved and accuracy of 95.78% on the test set, which so ar is the best model. Also a very high score on the training set, potentially a little overfit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
